{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from scipy import stats\n",
    "import itertools\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep the random state constant\n",
    "\n",
    "class RandomState(object):\n",
    "    def __init__(self, random_state=None):\n",
    "        self.random_state = random_state\n",
    "    def next(self, n=1):\n",
    "        assert type(n) == int, \"Ensure n is an integer\"\n",
    "        if n == 1:\n",
    "            self.random_state,\\\n",
    "                out_state = np.random.default_rng(\n",
    "                    self.random_state\n",
    "                    ).integers(0, 1e9, size=(2,))\n",
    "        else:\n",
    "            self.random_state,\\\n",
    "                *out_state = np.random.default_rng(\n",
    "                    self.random_state\n",
    "                    ).integers(0, 1e9, size=(n+1,))\n",
    "        \n",
    "        return out_state\n",
    "\n",
    "random_state = RandomState(42)\n",
    "torch.manual_seed(random_state.next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign source names to the dataset equally\n",
    "def assign_sources_equally(dataset, sources=('A', 'B', 'C', 'D', 'E', 'F')):\n",
    "    num_sources = len(sources)\n",
    "    num_data = len(dataset)\n",
    "    num_each = num_data // num_sources\n",
    "    \n",
    "    # Convert sources to a list if it's a tuple\n",
    "    sources_list = list(sources)\n",
    "    \n",
    "    # Create a list of source labels, each repeated equally\n",
    "    source_labels = sources_list * num_each + [sources_list[i] for i in range(num_data % num_sources)]\n",
    "    \n",
    "    # Shuffle the labels to randomize their order\n",
    "    np.random.shuffle(source_labels)\n",
    "    \n",
    "    return source_labels\n",
    "\n",
    "# Assign sources to training and test data\n",
    "training_sources = assign_sources_equally(training_data)\n",
    "test_sources = assign_sources_equally(test_data)\n",
    "\n",
    "# Example of how you can use the assigned sources\n",
    "print(\"First 10 source labels for training data:\", training_sources[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMNIST(Dataset):\n",
    "    def __init__(self, mnist_dataset, source_labels, transform=None):\n",
    "        \"\"\"\n",
    "        Custom dataset that applies a transform conditionally based on source labels.\n",
    "        \n",
    "        Args:\n",
    "        mnist_dataset (Dataset): The original MNIST dataset.\n",
    "        source_labels (list): List of source labels for each image in mnist_dataset.\n",
    "        transform (callable, optional): A function/transform to apply to the images.\n",
    "        \"\"\"\n",
    "        self.mnist_dataset = mnist_dataset\n",
    "        self.source_labels = source_labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mnist_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.mnist_dataset[idx]\n",
    "        source_label = self.source_labels[idx]\n",
    "\n",
    "        if source_label == 'A':\n",
    "            # Rotate the image by 180 degrees\n",
    "            image = transforms.functional.rotate(image, 180)\n",
    "        elif source_label == 'B':\n",
    "            # Randomly set 1/2 of the pixels to white (missing)\n",
    "            c, h, w = image.shape\n",
    "            num_pixels = h * w\n",
    "            num_missing = num_pixels // 2\n",
    "            mask = torch.randperm(num_pixels)[:num_missing]\n",
    "            mask_h, mask_w = mask // w, mask % w\n",
    "            image[:, mask_h, mask_w] = 1\n",
    "        elif source_label == 'C':\n",
    "            # Introduce noise\n",
    "            noise = torch.randn_like(image) * 0.5  # Adjust noise level as needed\n",
    "            image = image + noise\n",
    "            image = torch.clamp(image, 0, 1)  # Ensure pixel values are still valid\n",
    "        elif source_label == 'D':\n",
    "            # Apply label permutation for source D\n",
    "            label_permutation = {0: 9, 1: 8, 2: 7, 3: 6, 4: 5, 5: 4, 6: 3, 7: 2, 8: 1, 9: 0}\n",
    "            label = label_permutation[label]\n",
    "        elif source_label == 'E':\n",
    "            #keep the image as is\n",
    "            pass\n",
    "        elif source_label == 'F':\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"Unknown source label provided: must be 'A', 'B', or 'C', or 'D', or 'E'\")\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        image = torch.flatten(image)\n",
    "\n",
    "        return image, label, source_label\n",
    "\n",
    "\n",
    "# Create custom datasets\n",
    "custom_train_dataset = CustomMNIST(training_data, training_sources, transform=None)\n",
    "custom_test_dataset = CustomMNIST(test_data, test_sources, transform=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom model class with dropout\n",
    "class TunedMLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, dropout_rate):\n",
    "        super(TunedMLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, 100)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.linear2 = nn.Linear(100, 100)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.linear3 = nn.Linear(100, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.dropout2(x)\n",
    "        y_pred = self.linear3(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        source_correct = {source: 0 for source in 'ABCDEF'}\n",
    "        source_total = {source: 0 for source in 'ABCDEF'}\n",
    "\n",
    "        for images, labels, source_labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "            for source, pred, label in zip(source_labels, predicted, labels):\n",
    "                if pred == label:\n",
    "                    source_correct[source] += 1\n",
    "                source_total[source] += 1\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_accuracy = (correct_predictions / total_predictions) * 100\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "        for source in source_correct:\n",
    "            if source_total[source] > 0:\n",
    "                source_accuracy = (source_correct[source] / source_total[source]) * 100\n",
    "                print(f'Accuracy for Source {source}: {source_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid\n",
    "hyperparameter_grid = {\n",
    "    'lr': [0.001, 0.005, 0.01],\n",
    "    'dropout_rate': [0, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "# Cross-Validation for Hyperparameter Tuning\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "best_hyperparams = None\n",
    "\n",
    "# Create all possible combinations of hyperparameters\n",
    "all_combinations = list(product(*hyperparameter_grid.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comb in all_combinations:\n",
    "    lr, dropout_rate = comb\n",
    "    fold_results = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(custom_train_dataset)):\n",
    "        print(f'Fold {fold + 1} for hyperparameters: {comb}')\n",
    "\n",
    "        train_subset = Subset(custom_train_dataset, train_idx)\n",
    "        val_subset = Subset(custom_train_dataset, val_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_subset, batch_size=128, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=128, shuffle=False)\n",
    "\n",
    "        model = TunedMLP(input_size=784, output_size=10, dropout_rate=dropout_rate)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        train_model(model, train_loader, criterion, optimizer, num_epochs=5)\n",
    "\n",
    "        model.eval()\n",
    "        val_correct_predictions = 0\n",
    "        val_total_predictions = 0\n",
    "        source_correct = {source: 0 for source in 'ABCDEF'}\n",
    "        source_total = {source: 0 for source in 'ABCDEF'}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels, source_labels in val_loader:\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct_predictions += (predicted == labels).sum().item()\n",
    "                val_total_predictions += labels.size(0)\n",
    "\n",
    "                for source, pred, label in zip(source_labels, predicted, labels):\n",
    "                    if pred == label:\n",
    "                        source_correct[source] += 1\n",
    "                    source_total[source] += 1\n",
    "\n",
    "        val_accuracy = val_correct_predictions / val_total_predictions * 100.0\n",
    "        fold_results.append(val_accuracy)\n",
    "\n",
    "        print(f'Validation Accuracy for Fold {fold + 1}: {val_accuracy:.2f}%')\n",
    "        for source in source_correct:\n",
    "            if source_total[source] > 0:\n",
    "                source_accuracy = (source_correct[source] / source_total[source]) * 100\n",
    "                print(f'Validation Accuracy for Source {source}: {source_accuracy:.2f}%')\n",
    "\n",
    "    mean_val_accuracy = np.mean(fold_results)\n",
    "    std_val_accuracy = np.std(fold_results)\n",
    "    \n",
    "    print(f'Mean Validation Accuracy: {mean_val_accuracy:.2f}%')\n",
    "    print(f'Standard Deviation of Validation Accuracy: {std_val_accuracy:.2f}%')\n",
    "\n",
    "    if mean_val_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_val_accuracy\n",
    "        best_hyperparams = {'lr': lr, 'dropout_rate': dropout_rate}\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_hyperparams}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap accuracy function\n",
    "def bootstrap_accuracy(train_dataset, test_loader, best_hyperparams, num_bootstrap=5, sample_percentage=0.8):\n",
    "    accuracies = []\n",
    "    source_accuracies = {source: [] for source in 'ABCDEF'}\n",
    "\n",
    "    for _ in range(num_bootstrap):\n",
    "        bootstrap_indices = np.random.choice(len(train_dataset), size=int(len(train_dataset) * sample_percentage), replace=True)\n",
    "        bootstrap_subset = Subset(train_dataset, bootstrap_indices)\n",
    "        bootstrap_loader = DataLoader(bootstrap_subset, batch_size=128, shuffle=True)\n",
    "\n",
    "        model = TunedMLP(input_size=784, output_size=10, dropout_rate=best_hyperparams['dropout_rate'])\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=best_hyperparams['lr'])\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        train_model(model, bootstrap_loader, criterion, optimizer, num_epochs=10)\n",
    "\n",
    "        model.eval()\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        source_correct = {source: 0 for source in 'ABCDEF'}\n",
    "        source_total = {source: 0 for source in 'ABCDEF'}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels, source_labels in test_loader:\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                total_predictions += labels.size(0)\n",
    "\n",
    "                for source, pred, label in zip(source_labels, predicted, labels):\n",
    "                    if pred == label:\n",
    "                        source_correct[source] += 1\n",
    "                    source_total[source] += 1\n",
    "\n",
    "        overall_accuracy = correct_predictions / total_predictions * 100\n",
    "        accuracies.append(overall_accuracy)\n",
    "\n",
    "        for source in source_correct:\n",
    "            if source_total[source] > 0:\n",
    "                source_accuracy = (source_correct[source] / source_total[source]) * 100\n",
    "                source_accuracies[source].append(source_accuracy)\n",
    "\n",
    "    overall_mean = np.mean(accuracies)\n",
    "    overall_std = np.std(accuracies)\n",
    "\n",
    "    source_means = {source: np.mean(source_accuracies[source]) for source in source_accuracies}\n",
    "    source_stds = {source: np.std(source_accuracies[source]) for source in source_accuracies}\n",
    "\n",
    "    return overall_mean, overall_std, source_means, source_stds\n",
    "\n",
    "# Evaluate best model on test set using bootstrap sampling\n",
    "test_loader = DataLoader(custom_test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "print(\"Bootstrap evaluation on test set:\")\n",
    "test_mean, test_std, test_source_means, test_source_stds = bootstrap_accuracy(custom_train_dataset, test_loader, best_hyperparams)\n",
    "\n",
    "print(f\"Overall Test Accuracy: {test_mean:.2f}% ± {test_std:.2f}%\")\n",
    "for source in test_source_means:\n",
    "    print(f\"Test Accuracy for Source {source}: {test_source_means[source]:.2f}% ± {test_source_stds[source]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source fully separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with separate layers for each source\n",
    "class SourceMLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, dropout_rate):\n",
    "        super(SourceMLP, self).__init__()\n",
    "        self.networks = nn.ModuleDict({\n",
    "            source: nn.Sequential(\n",
    "                nn.Linear(input_size, 100),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(100, 100),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(100, output_size)\n",
    "            ) for source in 'ABCDEF'\n",
    "        })\n",
    "\n",
    "    def forward(self, x, source_labels):\n",
    "        outputs = [self.networks[source](x[i].unsqueeze(0)) for i, source in enumerate(source_labels)]\n",
    "        return torch.cat(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validate function\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        for images, labels, sources in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, sources)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        train_loss = total_loss / total\n",
    "        train_acc = correct / total * 100\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        source_counts = {s: 0 for s in 'ABCDEF'}\n",
    "        source_correct = {s: 0 for s in 'ABCDEF'}\n",
    "        with torch.no_grad():\n",
    "            for images, labels, sources in val_loader:\n",
    "                outputs = model(images, sources)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * labels.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "                for i, source in enumerate(sources):\n",
    "                    source_counts[source] += 1\n",
    "                    if predicted[i] == labels[i]:\n",
    "                        source_correct[source] += 1\n",
    "\n",
    "        val_loss /= val_total\n",
    "        val_acc = val_correct / val_total * 100\n",
    "        source_acc = {s: (source_correct[s] / source_counts[s] * 100) if source_counts[s] > 0 else 0 for s in 'ABCDEF'}\n",
    "\n",
    "        print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "        for s, acc in source_acc.items():\n",
    "            print(f'Source {s}: Validation Accuracy: {acc:.2f}%')\n",
    "    \n",
    "    return val_acc, source_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation and hyperparameter tuning\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "hyperparameter_grid = {'lr': [0.001, 0.005, 0.01], 'dropout_rate': [0, 0.2, 0.5]}\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "for lr, dropout_rate in itertools.product(*hyperparameter_grid.values()):\n",
    "    fold_accuracies = []\n",
    "    fold_source_accuracies = {source: [] for source in 'ABCDEF'}\n",
    "    print(f'Testing parameters: lr={lr}, dropout={dropout_rate}')\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(custom_train_dataset)):\n",
    "        print(f'Starting Fold {fold+1}')\n",
    "        train_subset = Subset(custom_train_dataset, train_idx)\n",
    "        val_subset = Subset(custom_train_dataset, val_idx)\n",
    "        train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=64, shuffle=False)\n",
    "\n",
    "        model = SourceMLP(784, 10, dropout_rate)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        accuracy, source_accuracies = train_and_validate(model, train_loader, val_loader, criterion, optimizer, 10)\n",
    "        fold_accuracies.append(accuracy)\n",
    "        for source in fold_source_accuracies:\n",
    "            fold_source_accuracies[source].append(np.mean(source_accuracies[source]))\n",
    "\n",
    "    mean_accuracy = np.mean(fold_accuracies)\n",
    "    std_accuracy = np.std(fold_accuracies)\n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_params = {'lr': lr, 'dropout_rate': dropout_rate}\n",
    "        best_model = model\n",
    "\n",
    "    print(f'Parameters: lr={lr}, dropout={dropout_rate}, Mean Accuracy: {mean_accuracy:.2f}%, Std Dev: {std_accuracy:.2f}%')\n",
    "    for source in fold_source_accuracies:\n",
    "        mean_source = np.mean(fold_source_accuracies[source])\n",
    "        std_source = np.std(fold_source_accuracies[source])\n",
    "        print(f'Source {source} - Mean: {mean_source:.2f}%, Std Dev: {std_source:.2f}%')\n",
    "\n",
    "print(f'Best Model Parameters: {best_params}, with accuracy: {best_accuracy:.2f}%, Std Dev: {std_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap sampling and testing\n",
    "bootstrap_accuracies = []\n",
    "source_bootstrap_accuracies = {source: [] for source in 'ABCDEF'}\n",
    "for i in range(5):\n",
    "    indices = np.random.choice(len(custom_train_dataset), size=int(0.8 * len(custom_train_dataset)), replace=False)\n",
    "    bootstrap_subset = Subset(custom_train_dataset, indices)\n",
    "    bootstrap_loader = DataLoader(bootstrap_subset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(custom_test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    # Initialize the model with the best hyperparameters\n",
    "    model = SourceMLP(784, 10, best_params['dropout_rate'])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=best_params['lr'])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(f'Bootstrap iteration {i+1}')\n",
    "    test_accuracy, source_accuracies = train_and_validate(model, bootstrap_loader, test_loader, criterion, optimizer, 10)\n",
    "    bootstrap_accuracies.append(test_accuracy)\n",
    "    for source in source_accuracies:\n",
    "        source_bootstrap_accuracies[source].append(np.mean(source_accuracies[source]))\n",
    "\n",
    "mean_bootstrap = np.mean(bootstrap_accuracies)\n",
    "std_bootstrap = np.std(bootstrap_accuracies)\n",
    "print(f'Bootstrap results: Mean accuracy: {mean_bootstrap:.2f}%, Std Dev: {std_bootstrap:.2f}%')\n",
    "for source in source_bootstrap_accuracies:\n",
    "    mean_source = np.mean(source_bootstrap_accuracies[source])\n",
    "    std_source = np.std(source_bootstrap_accuracies[source])\n",
    "    print(f'Source {source} - Bootstrap Mean: {mean_source:.2f}%, Std Dev: {std_source:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source final layer separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SourceMLP2(nn.Module):\n",
    "    def __init__(self, input_size, output_size, dropout_rate):\n",
    "        super(SourceMLP2, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, 100)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.linear2 = nn.Linear(100, 100)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.final_layers = nn.ModuleDict({\n",
    "            'A': nn.Linear(100, output_size),\n",
    "            'B': nn.Linear(100, output_size),\n",
    "            'C': nn.Linear(100, output_size),\n",
    "            'D': nn.Linear(100, output_size),\n",
    "            'E': nn.Linear(100, output_size),\n",
    "            'F': nn.Linear(100, output_size)\n",
    "        })\n",
    "\n",
    "    def forward(self, data, sources):\n",
    "        x = F.relu(self.linear1(data))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.dropout2(x)\n",
    "        outputs = [self.final_layers[source](x[i].unsqueeze(0)) for i, source in enumerate(sources)]\n",
    "        return torch.cat(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validate function\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        for images, labels, sources in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, sources)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        train_loss = total_loss / total\n",
    "        train_acc = correct / total * 100\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        source_counts = {s: 0 for s in 'ABCDEF'}\n",
    "        source_correct = {s: 0 for s in 'ABCDEF'}\n",
    "        with torch.no_grad():\n",
    "            for images, labels, sources in val_loader:\n",
    "                outputs = model(images, sources)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * labels.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "                for i, source in enumerate(sources):\n",
    "                    source_counts[source] += 1\n",
    "                    if predicted[i] == labels[i]:\n",
    "                        source_correct[source] += 1\n",
    "\n",
    "        val_loss /= val_total\n",
    "        val_acc = val_correct / val_total * 100\n",
    "        source_acc = {s: (source_correct[s] / source_counts[s] * 100) if source_counts[s] > 0 else 0 for s in 'ABCDEF'}\n",
    "\n",
    "        print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "        for s, acc in source_acc.items():\n",
    "            print(f'Source {s}: Validation Accuracy: {acc:.2f}%')\n",
    "    \n",
    "    return val_acc, source_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation and hyperparameter tuning\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "hyperparameter_grid = {'lr': [0.001, 0.005, 0.01], 'dropout_rate': [0, 0.2, 0.5]}\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "for lr, dropout_rate in itertools.product(*hyperparameter_grid.values()):\n",
    "    fold_accuracies = []\n",
    "    fold_source_accuracies = {source: [] for source in 'ABCDEF'}\n",
    "    print(f'Testing parameters: lr={lr}, dropout={dropout_rate}')\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(custom_train_dataset)):\n",
    "        print(f'Starting Fold {fold+1}')\n",
    "        train_subset = Subset(custom_train_dataset, train_idx)\n",
    "        val_subset = Subset(custom_train_dataset, val_idx)\n",
    "        train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=64, shuffle=False)\n",
    "\n",
    "        model = SourceMLP2(784, 10, dropout_rate)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        accuracy, source_accuracies = train_and_validate(model, train_loader, val_loader, criterion, optimizer, 10)\n",
    "        fold_accuracies.append(accuracy)\n",
    "        for source in fold_source_accuracies:\n",
    "            fold_source_accuracies[source].append(np.mean(source_accuracies[source]))\n",
    "\n",
    "    mean_accuracy = np.mean(fold_accuracies)\n",
    "    std_accuracy = np.std(fold_accuracies)\n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_params = {'lr': lr, 'dropout_rate': dropout_rate}\n",
    "        best_model = model\n",
    "\n",
    "    print(f'Parameters: lr={lr}, dropout={dropout_rate}, Mean Accuracy: {mean_accuracy:.2f}%, Std Dev: {std_accuracy:.2f}%')\n",
    "    for source in fold_source_accuracies:\n",
    "        mean_source = np.mean(fold_source_accuracies[source])\n",
    "        std_source = np.std(fold_source_accuracies[source])\n",
    "        print(f'Source {source} - Mean: {mean_source:.2f}%, Std Dev: {std_source:.2f}%')\n",
    "\n",
    "print(f'Best Model Parameters: {best_params}, with accuracy: {best_accuracy:.2f}%, Std Dev: {std_accuracy:.2f}%')\n",
    "\n",
    "# Bootstrap sampling and testing\n",
    "bootstrap_accuracies = []\n",
    "source_bootstrap_accuracies = {source: [] for source in 'ABCDEF'}\n",
    "for i in range(5):\n",
    "    indices = np.random.choice(len(custom_train_dataset), size=int(0.8 * len(custom_train_dataset)), replace=False)\n",
    "    bootstrap_subset = Subset(custom_train_dataset, indices)\n",
    "    bootstrap_loader = DataLoader(bootstrap_subset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(custom_test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    print(f'Bootstrap iteration {i+1}')\n",
    "    test_accuracy, source_accuracies = train_and_validate(best_model, bootstrap_loader, test_loader, criterion, optimizer, 10)\n",
    "    bootstrap_accuracies.append(test_accuracy)\n",
    "    for source in source_accuracies:\n",
    "        source_bootstrap_accuracies[source].append(np.mean(source_accuracies[source]))\n",
    "\n",
    "mean_bootstrap = np.mean(bootstrap_accuracies)\n",
    "std_bootstrap = np.std(bootstrap_accuracies)\n",
    "print(f'Bootstrap results: Mean accuracy: {mean_bootstrap:.2f}%, Std Dev: {std_bootstrap:.2f}%')\n",
    "for source in source_bootstrap_accuracies:\n",
    "    mean_source = np.mean(source_bootstrap_accuracies[source])\n",
    "    std_source = np.std(source_bootstrap_accuracies[source])\n",
    "    print(f'Source {source} - Bootstrap Mean: {mean_source:.2f}%, Std Dev: {std_source:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
