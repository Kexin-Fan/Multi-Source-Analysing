{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import itertools\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign source names to the dataset equally\n",
    "def assign_sources_equally(dataset, sources=('A', 'B', 'C', 'D', 'E','F')):\n",
    "    num_sources = len(sources)\n",
    "    num_data = len(dataset)\n",
    "    num_each = num_data // num_sources\n",
    "    \n",
    "    # Convert sources to a list if it's a tuple\n",
    "    sources_list = list(sources)\n",
    "    \n",
    "    # Create a list of source labels, each repeated equally\n",
    "    source_labels = sources_list * num_each + [sources_list[i] for i in range(num_data % num_sources)]\n",
    "    \n",
    "    # Shuffle the labels to randomize their order\n",
    "    np.random.shuffle(source_labels)\n",
    "    \n",
    "    return source_labels\n",
    "\n",
    "# Assign sources to training and test data\n",
    "training_sources = assign_sources_equally(training_data)\n",
    "test_sources = assign_sources_equally(test_data)\n",
    "\n",
    "# Example of how you can use the assigned sources\n",
    "print(\"First 10 source labels for training data:\", training_sources[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_participants_to_train_and_test(train_labels, test_labels, num_participants_per_source, train_images_per_participant):\n",
    "    participants = {source: [] for source in set(train_labels)}\n",
    "    global_participant_id = 0\n",
    "    \n",
    "    # Calculate number of test images for participants\n",
    "    num_participants_total = num_participants_per_source * len(participants)\n",
    "    test_images_per_participant = 10000 // num_participants_total\n",
    "    extra_test_images = 10000 % num_participants_total\n",
    "\n",
    "    for source in participants:\n",
    "        train_indices = [i for i, s in enumerate(train_labels) if s == source]\n",
    "        test_indices = [i for i, s in enumerate(test_labels) if s == source]\n",
    "\n",
    "        np.random.shuffle(train_indices)\n",
    "        np.random.shuffle(test_indices)\n",
    "\n",
    "        for i in range(num_participants_per_source):\n",
    "            train_participant_indices = train_indices[i * train_images_per_participant: (i + 1) * train_images_per_participant]\n",
    "            \n",
    "            # Assign 166 or 167 test images per participant\n",
    "            if global_participant_id < extra_test_images:\n",
    "                test_participant_indices = test_indices[i * test_images_per_participant: (i + 1) * test_images_per_participant + 1]\n",
    "            else:\n",
    "                test_participant_indices = test_indices[i * test_images_per_participant: (i + 1) * test_images_per_participant]\n",
    "            \n",
    "            participants[source].append((global_participant_id, train_participant_indices, test_participant_indices))\n",
    "            global_participant_id += 1\n",
    "\n",
    "    return participants\n",
    "\n",
    "# Parameters\n",
    "num_participants_per_source = 10\n",
    "train_images_per_participant = 1000\n",
    "\n",
    "# Assign participant IDs to both training and test data\n",
    "participants = assign_participants_to_train_and_test(training_sources, test_sources, num_participants_per_source, train_images_per_participant)\n",
    "\n",
    "# Example of how you can use the assigned participants\n",
    "for source, participant_info in participants.items():\n",
    "    print(f\"Source: {source}\")\n",
    "    for participant_id, train_indices, test_indices in participant_info:\n",
    "        print(f\"  Participant {participant_id} - Train Indices: {train_indices[:10]}..., Test Indices: {test_indices[:10]}...\")\n",
    "\n",
    "# Output first 10 source labels for training data\n",
    "print(\"First 10 source labels for training data:\", training_sources[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticipantCustomMNIST(Dataset):\n",
    "    def __init__(self, mnist_dataset, source_labels, participants, transform=None, train=True):\n",
    "        self.mnist_dataset = mnist_dataset\n",
    "        self.source_labels = source_labels\n",
    "        self.participants = participants\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "\n",
    "        self.data = self._create_data()\n",
    "\n",
    "    def _create_data(self):\n",
    "        data = []\n",
    "        for source, participant_data in self.participants.items():\n",
    "            for participant_id, train_indices, test_indices in participant_data:\n",
    "                indices = train_indices if self.train else test_indices\n",
    "                for idx in indices:\n",
    "                    image, label = self.mnist_dataset[idx]\n",
    "                    source_label = self.source_labels[idx]\n",
    "                    data.append((image, label, source_label, participant_id))\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label, source_label, participant_id = self.data[idx]\n",
    "\n",
    "        if source_label == 'A':\n",
    "            image = transforms.functional.rotate(image, 180)\n",
    "        elif source_label == 'B':\n",
    "            c, h, w = image.shape\n",
    "            num_pixels = h * w\n",
    "            num_missing = num_pixels // 2\n",
    "            mask = torch.randperm(num_pixels)[:num_missing]\n",
    "            mask_h, mask_w = mask // w, mask % w\n",
    "            image[:, mask_h, mask_w] = 1\n",
    "        elif source_label == 'C':\n",
    "            noise = torch.randn_like(image) * 0.5\n",
    "            image = image + noise\n",
    "            image = torch.clamp(image, 0, 1)\n",
    "        elif source_label == 'D':\n",
    "            label_permutation = {0: 9, 1: 8, 2: 7, 3: 6, 4: 5, 5: 4, 6: 3, 7: 2, 8: 1, 9: 0}\n",
    "            label = label_permutation[label]\n",
    "        elif source_label == 'E':\n",
    "            pass\n",
    "        elif source_label == 'F':\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"Unknown source label provided: must be 'A', 'B', 'C', 'D', or 'E', or 'F'\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        image = torch.flatten(image)\n",
    "        return image, label, source_label, participant_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom datasets with participants\n",
    "train_dataset = ParticipantCustomMNIST(training_data, training_sources, participants, transform=None, train=True)\n",
    "test_dataset = ParticipantCustomMNIST(test_data, test_sources, participants, transform=None, train=False)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels, source_labels, participant_ids in train_loader:\n",
    "    print(\"Images shape:\", images.shape)\n",
    "    print(\"Labels shape:\", labels.shape)\n",
    "\n",
    "    print(\"Participant IDs shape:\", participant_ids.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingMLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_patient_ids, embedding_dim, dropout_rate):\n",
    "        super(EmbeddingMLP, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_patient_ids, embedding_dim=embedding_dim)\n",
    "        self.linear1 = nn.Linear(input_size + embedding_dim, 100)\n",
    "        self.linear2 = nn.Linear(100, 100)\n",
    "        self.linear3 = nn.Linear(100, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def forward(self, data, participant_ids):\n",
    "        # Embed the participant IDs\n",
    "        embedded_ids = self.embedding(participant_ids)\n",
    "\n",
    "        # Concatenate the embedded participant IDs with the input data\n",
    "        x = torch.cat((data, embedded_ids), dim=1)\n",
    "\n",
    "        # Pass through the MLP layers\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.dropout(x)\n",
    "        y_pred = self.linear3(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train_model function\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        # Initialize source-specific counters\n",
    "        source_correct = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0}\n",
    "        source_total = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0}\n",
    "\n",
    "        for batch_idx, (images, labels, source_labels, participant_ids) in enumerate(train_loader):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, participant_ids)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update running loss\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update source-specific counters\n",
    "            for i, (source, pred, label) in enumerate(zip(source_labels, predicted, labels)):\n",
    "                if pred == label:\n",
    "                    source_correct[source] += 1\n",
    "                source_total[source] += 1\n",
    "\n",
    "        # Calculate epoch loss and overall accuracy\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_accuracy = (correct_predictions / total_predictions) * 100\n",
    "\n",
    "        # Display overall accuracy and loss\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "\n",
    "        # Display source-specific accuracies\n",
    "        for source in source_correct:\n",
    "            if source_total[source] > 0:\n",
    "                source_accuracy = (source_correct[source] / source_total[source]) * 100\n",
    "                print(f'Accuracy for Source {source}: {source_accuracy:.2f}%')\n",
    "\n",
    "def validate_model(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    source_correct = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0}\n",
    "    source_total = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels, source_labels, participant_ids) in enumerate(val_loader):\n",
    "            outputs = model(images, participant_ids)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "            for source, pred, label in zip(source_labels, predicted, labels):\n",
    "                if pred == label:\n",
    "                    source_correct[source] += 1\n",
    "                source_total[source] += 1\n",
    "\n",
    "    val_loss = val_running_loss / len(val_loader.dataset)\n",
    "    val_accuracy = correct_predictions / total_predictions * 100.0\n",
    "\n",
    "    source_accuracies = {}\n",
    "    for source in source_correct:\n",
    "        if source_total[source] > 0:\n",
    "            source_accuracy = (source_correct[source] / source_total[source]) * 100\n",
    "            source_accuracies[source] = source_accuracy\n",
    "\n",
    "    return val_loss, val_accuracy, source_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid\n",
    "hyperparameter_grid = {\n",
    "    'lr': [0.001, 0.005, 0.01],\n",
    "    'dropout_rate': [0, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model_state = None\n",
    "best_hyperparams = None\n",
    "\n",
    "# Create all possible combinations of hyperparameters\n",
    "all_combinations = list(itertools.product(*hyperparameter_grid.values()))\n",
    "\n",
    "# Cross-validation and hyperparameter tuning\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for lr, dropout_rate in all_combinations:\n",
    "    fold_accuracies = []\n",
    "    fold_source_accuracies = {'A': [], 'B': [], 'C': [], 'D': [], 'E': [], 'F': []}\n",
    "    print(f'Testing parameters: lr={lr}, dropout_rate={dropout_rate}')\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(range(len(train_dataset)))):\n",
    "        print(f'Starting Fold {fold+1}')\n",
    "        train_subset = Subset(train_dataset, train_idx)\n",
    "        val_subset = Subset(train_dataset, val_idx)\n",
    "        train_loader = DataLoader(train_subset, batch_size=128, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=128, shuffle=False)\n",
    "\n",
    "        model = EmbeddingMLP(input_size=784, output_size=10, num_patient_ids=num_participants_per_source * 6, embedding_dim=10, dropout_rate=dropout_rate)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n",
    "        val_loss, val_acc, source_accuracies = validate_model(model, val_loader, criterion)\n",
    "        fold_accuracies.append(val_acc)\n",
    "        for source in source_accuracies:\n",
    "            fold_source_accuracies[source].append(source_accuracies[source])\n",
    "\n",
    "    mean_accuracy = np.mean(fold_accuracies)\n",
    "    std_accuracy = np.std(fold_accuracies)\n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_hyperparams = {'lr': lr, 'dropout_rate': dropout_rate}\n",
    "        best_model = model\n",
    "\n",
    "    print(f'Parameters: lr={lr}, dropout_rate={dropout_rate}, Mean Accuracy: {mean_accuracy:.2f}%, Std Dev: {std_accuracy:.2f}%')\n",
    "    for source in fold_source_accuracies:\n",
    "        mean_source = np.mean(fold_source_accuracies[source])\n",
    "        std_source = np.std(fold_source_accuracies[source])\n",
    "        print(f'Source {source} - Mean: {mean_source:.2f}%, Std Dev: {std_source:.2f}%')\n",
    "\n",
    "print(f'Best Hyperparameters: {best_hyperparams}, with mean accuracy: {best_accuracy:.2f}%, Std Dev: {std_accuracy:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap sampling and testing\n",
    "def bootstrap_train_and_test(model, train_data, test_loader, criterion, optimizer_params, num_epochs=10, num_bootstrap=5, sample_percentage=0.8):\n",
    "    bootstrap_accuracies = []\n",
    "    source_bootstrap_accuracies = {source: [] for source in 'ABCDEF'}\n",
    "    for i in range(num_bootstrap):\n",
    "        # Create a bootstrap sample from the training data\n",
    "        indices = np.random.choice(len(train_data), size=int(sample_percentage * len(train_data)), replace=False)\n",
    "        bootstrap_subset = Subset(train_data, indices)\n",
    "        bootstrap_loader = DataLoader(bootstrap_subset, batch_size=128, shuffle=True)\n",
    "\n",
    "        # Initialize and train the model\n",
    "        model.apply(lambda m: m.reset_parameters() if hasattr(m, 'reset_parameters') else None)  # Reset model parameters\n",
    "        optimizer = torch.optim.Adam(model.parameters(), **optimizer_params)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            for images, labels, source_labels, participant_ids in bootstrap_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images, participant_ids)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Evaluate on the test set\n",
    "        model.eval()\n",
    "        test_loss, correct, total = 0, 0, 0\n",
    "        source_counts = {s: 0 for s in 'ABCDEF'}\n",
    "        source_correct = {s: 0 for s in 'ABCDEF'}\n",
    "        with torch.no_grad():\n",
    "            for images, labels, source_labels, participant_ids in test_loader:\n",
    "                outputs = model(images, participant_ids)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item() * labels.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "                for i, source in enumerate(source_labels):  # Assuming source labels are in the labels (change if different)\n",
    "                    source_counts[source] += 1\n",
    "                    if predicted[i] == labels[i]:\n",
    "                        source_correct[source] += 1\n",
    "\n",
    "        accuracy = correct / total * 100.0\n",
    "        bootstrap_accuracies.append(accuracy)\n",
    "        source_accuracies = {s: (source_correct[s] / source_counts[s] * 100) if source_counts[s] > 0 else 0 for s in 'ABCDEF'}\n",
    "        for source in source_accuracies:\n",
    "            source_bootstrap_accuracies[source].append(source_accuracies[source])\n",
    "\n",
    "    mean_accuracy = np.mean(bootstrap_accuracies)\n",
    "    std_accuracy = np.std(bootstrap_accuracies)\n",
    "    mean_source_accuracies = {s: np.mean(source_bootstrap_accuracies[s]) for s in 'ABCDEF'}\n",
    "    std_source_accuracies = {s: np.std(source_bootstrap_accuracies[s]) for s in 'ABCDEF'}\n",
    "\n",
    "    return mean_accuracy, std_accuracy, mean_source_accuracies, std_source_accuracies\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Perform bootstrap training and testing\n",
    "mean_bootstrap, std_bootstrap, mean_source_accuracies, std_source_accuracies = bootstrap_train_and_test(\n",
    "    best_model, train_dataset, test_loader, criterion, {'lr': best_hyperparams['lr']}, num_epochs=10\n",
    ")\n",
    "\n",
    "print(f'Bootstrap results: Mean accuracy: {mean_bootstrap:.2f}%, Std Dev: {std_bootstrap:.2f}%')\n",
    "for source in mean_source_accuracies:\n",
    "    print(f'Source {source} - Bootstrap Mean: {mean_source_accuracies[source]:.2f}%, Std Dev: {std_source_accuracies[source]:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_mapping = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5}\n",
    "\n",
    "# Function to map source labels to indices\n",
    "def map_source_labels_to_indices(source_labels):\n",
    "    return [source_mapping[source] for source in source_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SourceEmbeddingMLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_sources, embedding_dim, dropout_rate):\n",
    "        super(SourceEmbeddingMLP, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_sources, embedding_dim=embedding_dim)\n",
    "        self.linear1 = nn.Linear(input_size + embedding_dim, 100)\n",
    "        self.linear2 = nn.Linear(100, 100)\n",
    "        self.linear3 = nn.Linear(100, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def forward(self, data, source_ids):\n",
    "        # Embed the source IDs\n",
    "        embedded_ids = self.embedding(source_ids)\n",
    "\n",
    "        # Concatenate the embedded source IDs with the input data\n",
    "        x = torch.cat((data, embedded_ids), dim=1)\n",
    "\n",
    "        # Pass through the MLP layers\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.dropout(x)\n",
    "        y_pred = self.linear3(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train_model function\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        # Initialize source-specific counters\n",
    "        source_correct = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0}\n",
    "        source_total = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0}\n",
    "\n",
    "        for batch_idx, (images, labels, source_labels, participant_ids) in enumerate(train_loader):\n",
    "            # Convert source_labels to tensor of source IDs\n",
    "            source_ids = torch.tensor(map_source_labels_to_indices(source_labels), dtype=torch.long)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, source_ids)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update running loss\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update source-specific counters\n",
    "            for i, (source, pred, label) in enumerate(zip(source_labels, predicted, labels)):\n",
    "                if pred == label:\n",
    "                    source_correct[source] += 1\n",
    "                source_total[source] += 1\n",
    "\n",
    "        # Calculate epoch loss and overall accuracy\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_accuracy = (correct_predictions / total_predictions) * 100\n",
    "\n",
    "        # Display overall accuracy and loss\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "\n",
    "        # Display source-specific accuracies\n",
    "        for source in source_correct:\n",
    "            if source_total[source] > 0:\n",
    "                source_accuracy = (source_correct[source] / source_total[source]) * 100\n",
    "                print(f'Accuracy for Source {source}: {source_accuracy:.2f}%')\n",
    "\n",
    "def validate_model(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    source_correct = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0}\n",
    "    source_total = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels, source_labels, participant_ids) in enumerate(val_loader):\n",
    "            # Convert source_labels to tensor of source IDs\n",
    "            source_ids = torch.tensor(map_source_labels_to_indices(source_labels), dtype=torch.long)\n",
    "\n",
    "            outputs = model(images, source_ids)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "            for source, pred, label in zip(source_labels, predicted, labels):\n",
    "                if pred == label:\n",
    "                    source_correct[source] += 1\n",
    "                source_total[source] += 1\n",
    "\n",
    "    val_loss = val_running_loss / len(val_loader.dataset)\n",
    "    val_accuracy = correct_predictions / total_predictions * 100.0\n",
    "\n",
    "    source_accuracies = {}\n",
    "    for source in source_correct:\n",
    "        if source_total[source] > 0:\n",
    "            source_accuracy = (source_correct[source] / source_total[source]) * 100\n",
    "            source_accuracies[source] = source_accuracy\n",
    "\n",
    "    return val_loss, val_accuracy, source_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid\n",
    "hyperparameter_grid = {\n",
    "    'lr': [0.001, 0.005, 0.01],\n",
    "    'dropout_rate': [0, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model_state = None\n",
    "best_hyperparams = None\n",
    "\n",
    "# Create all possible combinations of hyperparameters\n",
    "all_combinations = list(itertools.product(*hyperparameter_grid.values()))\n",
    "\n",
    "# Cross-validation and hyperparameter tuning\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for lr, dropout_rate in all_combinations:\n",
    "    fold_accuracies = []\n",
    "    fold_source_accuracies = {'A': [], 'B': [], 'C': [], 'D': [], 'E': [], 'F': []}\n",
    "    print(f'Testing parameters: lr={lr}, dropout_rate={dropout_rate}')\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(range(len(train_dataset)))):\n",
    "        print(f'Starting Fold {fold+1}')\n",
    "        train_subset = Subset(train_dataset, train_idx)\n",
    "        val_subset = Subset(train_dataset, val_idx)\n",
    "        train_loader = DataLoader(train_subset, batch_size=128, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=128, shuffle=False)\n",
    "\n",
    "        model = SourceEmbeddingMLP(input_size=784, output_size=10, num_sources=6, embedding_dim=3, dropout_rate=dropout_rate)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n",
    "        val_loss, val_acc, source_accuracies = validate_model(model, val_loader, criterion)\n",
    "        fold_accuracies.append(val_acc)\n",
    "        for source in source_accuracies:\n",
    "            fold_source_accuracies[source].append(source_accuracies[source])\n",
    "\n",
    "    mean_accuracy = np.mean(fold_accuracies)\n",
    "    std_accuracy = np.std(fold_accuracies)\n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_hyperparams = {'lr': lr, 'dropout_rate': dropout_rate}\n",
    "        best_model = model\n",
    "\n",
    "    print(f'Parameters: lr={lr}, dropout_rate={dropout_rate}, Mean Accuracy: {mean_accuracy:.2f}%, Std Dev: {std_accuracy:.2f}%')\n",
    "    for source in fold_source_accuracies:\n",
    "        mean_source = np.mean(fold_source_accuracies[source])\n",
    "        std_source = np.std(fold_source_accuracies[source])\n",
    "        print(f'Source {source} - Mean: {mean_source:.2f}%, Std Dev: {std_source:.2f}%')\n",
    "\n",
    "print(f'Best Hyperparameters: {best_hyperparams}, with mean accuracy: {best_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap sampling and testing\n",
    "def bootstrap_train_and_test(model, train_data, test_loader, criterion, optimizer_params, num_epochs=10, num_bootstrap=5, sample_percentage=0.8):\n",
    "    bootstrap_accuracies = []\n",
    "    source_bootstrap_accuracies = {source: [] for source in 'ABCDEF'}\n",
    "    for i in range(num_bootstrap):\n",
    "        # Create a bootstrap sample from the training data\n",
    "        indices = np.random.choice(len(train_data), size=int(sample_percentage * len(train_data)), replace=False)\n",
    "        bootstrap_subset = Subset(train_data, indices)\n",
    "        bootstrap_loader = DataLoader(bootstrap_subset, batch_size=128, shuffle=True)\n",
    "\n",
    "        # Initialize and train the model\n",
    "        optimizer = torch.optim.Adam(model.parameters(), **optimizer_params)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            for images, labels, source_labels, participant_ids in bootstrap_loader:\n",
    "                # Convert source_labels to tensor of source IDs\n",
    "                source_ids = torch.tensor(map_source_labels_to_indices(source_labels), dtype=torch.long)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images, source_ids)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Evaluate on the test set\n",
    "        model.eval()\n",
    "        test_loss, correct, total = 0, 0, 0\n",
    "        source_counts = {s: 0 for s in 'ABCDEF'}\n",
    "        source_correct = {s: 0 for s in 'ABCDEF'}\n",
    "        with torch.no_grad():\n",
    "            for images, labels, source_labels, participant_ids in test_loader:\n",
    "                # Convert source_labels to tensor of source IDs\n",
    "                source_ids = torch.tensor(map_source_labels_to_indices(source_labels), dtype=torch.long)\n",
    "\n",
    "                outputs = model(images, source_ids)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item() * labels.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "                for i, source in enumerate(source_labels):\n",
    "                    source_counts[source] += 1\n",
    "                    if predicted[i] == labels[i]:\n",
    "                        source_correct[source] += 1\n",
    "\n",
    "        accuracy = correct / total * 100.0\n",
    "        bootstrap_accuracies.append(accuracy)\n",
    "        source_accuracies = {s: (source_correct[s] / source_counts[s] * 100) if source_counts[s] > 0 else 0 for s in 'ABCDEF'}\n",
    "        for source in source_accuracies:\n",
    "            source_bootstrap_accuracies[source].append(source_accuracies[source])\n",
    "\n",
    "    mean_accuracy = np.mean(bootstrap_accuracies)\n",
    "    std_accuracy = np.std(bootstrap_accuracies)\n",
    "    mean_source_accuracies = {s: np.mean(source_bootstrap_accuracies[s]) for s in 'ABCDEF'}\n",
    "    std_source_accuracies = {s: np.std(source_bootstrap_accuracies[s]) for s in 'ABCDEF'}\n",
    "\n",
    "    return mean_accuracy, std_accuracy, mean_source_accuracies, std_source_accuracies\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Perform bootstrap training and testing\n",
    "mean_bootstrap, std_bootstrap, mean_source_accuracies, std_source_accuracies = bootstrap_train_and_test(\n",
    "    best_model, train_dataset, test_loader, criterion, {'lr': best_hyperparams['lr']}, num_epochs=10\n",
    ")\n",
    "\n",
    "print(f'Bootstrap results: Mean accuracy: {mean_bootstrap:.2f}%, Std Dev: {std_bootstrap:.2f}%')\n",
    "for source in mean_source_accuracies:\n",
    "    print(f'Source {source} - Bootstrap Mean: {mean_source_accuracies[source]:.2f}%, Std Dev: {std_source_accuracies[source]:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatMLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, dropout_rate):\n",
    "        super(ConcatMLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size + 1, 100)  # +1 for the source ID\n",
    "        self.linear2 = nn.Linear(100, 100)\n",
    "        self.linear3 = nn.Linear(100, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x = F.relu(self.linear1(data))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.dropout(x)\n",
    "        y_pred = self.linear3(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train_model function\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        # Initialize source-specific counters\n",
    "        source_correct = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0}\n",
    "        source_total = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0}\n",
    "\n",
    "        for batch_idx, (images, labels, source_labels, participant_ids) in enumerate(train_loader):\n",
    "            # Convert source_labels to tensor of source IDs\n",
    "            source_ids = torch.tensor(map_source_labels_to_indices(source_labels), dtype=torch.long)\n",
    "            source_ids = source_ids.unsqueeze(1).float()  # Convert to float and unsqueeze\n",
    "\n",
    "            # Concatenate the source IDs with the input data\n",
    "            inputs = torch.cat((images, source_ids), dim=1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update running loss\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update source-specific counters\n",
    "            for i, (source, pred, label) in enumerate(zip(source_labels, predicted, labels)):\n",
    "                if pred == label:\n",
    "                    source_correct[source] += 1\n",
    "                source_total[source] += 1\n",
    "\n",
    "        # Calculate epoch loss and overall accuracy\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_accuracy = (correct_predictions / total_predictions) * 100\n",
    "\n",
    "        # Display overall accuracy and loss\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "\n",
    "        # Display source-specific accuracies\n",
    "        for source in source_correct:\n",
    "            if source_total[source] > 0:\n",
    "                source_accuracy = (source_correct[source] / source_total[source]) * 100\n",
    "                print(f'Accuracy for Source {source}: {source_accuracy:.2f}%')\n",
    "\n",
    "def validate_model(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    source_correct = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0}\n",
    "    source_total = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels, source_labels, participant_ids) in enumerate(val_loader):\n",
    "            # Convert source_labels to tensor of source IDs\n",
    "            source_ids = torch.tensor(map_source_labels_to_indices(source_labels), dtype=torch.long)\n",
    "            source_ids = source_ids.unsqueeze(1).float()  # Convert to float and unsqueeze\n",
    "\n",
    "            # Concatenate the source IDs with the input data\n",
    "            inputs = torch.cat((images, source_ids), dim=1)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "            for source, pred, label in zip(source_labels, predicted, labels):\n",
    "                if pred == label:\n",
    "                    source_correct[source] += 1\n",
    "                source_total[source] += 1\n",
    "\n",
    "    val_loss = val_running_loss / len(val_loader.dataset)\n",
    "    val_accuracy = correct_predictions / total_predictions * 100.0\n",
    "\n",
    "    source_accuracies = {}\n",
    "    for source in source_correct:\n",
    "        if source_total[source] > 0:\n",
    "            source_accuracy = (source_correct[source] / source_total[source]) * 100\n",
    "            source_accuracies[source] = source_accuracy\n",
    "\n",
    "    return val_loss, val_accuracy, source_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid\n",
    "hyperparameter_grid = {\n",
    "    'lr': [0.001, 0.005, 0.01],\n",
    "    'dropout_rate': [0, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model_state = None\n",
    "best_hyperparams = None\n",
    "\n",
    "# Create all possible combinations of hyperparameters\n",
    "all_combinations = list(itertools.product(*hyperparameter_grid.values()))\n",
    "\n",
    "# Cross-validation and hyperparameter tuning\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for lr, dropout_rate in all_combinations:\n",
    "    fold_accuracies = []\n",
    "    fold_source_accuracies = {'A': [], 'B': [], 'C': [], 'D': [], 'E': [], 'F': []}\n",
    "    print(f'Testing parameters: lr={lr}, dropout_rate={dropout_rate}')\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(range(len(train_dataset)))):\n",
    "        print(f'Starting Fold {fold+1}')\n",
    "        train_subset = Subset(train_dataset, train_idx)\n",
    "        val_subset = Subset(train_dataset, val_idx)\n",
    "        train_loader = DataLoader(train_subset, batch_size=128, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=128, shuffle=False)\n",
    "\n",
    "        model = ConcatMLP(input_size=784, output_size=10, dropout_rate=dropout_rate)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n",
    "        val_loss, val_acc, source_accuracies = validate_model(model, val_loader, criterion)\n",
    "        fold_accuracies.append(val_acc)\n",
    "        for source in source_accuracies:\n",
    "            fold_source_accuracies[source].append(source_accuracies[source])\n",
    "\n",
    "    mean_accuracy = np.mean(fold_accuracies)\n",
    "    std_accuracy = np.std(fold_accuracies)\n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_hyperparams = {'lr': lr, 'dropout_rate': dropout_rate}\n",
    "        best_model = model\n",
    "\n",
    "    print(f'Parameters: lr={lr}, dropout_rate={dropout_rate}, Mean Accuracy: {mean_accuracy:.2f}%, Std Dev: {std_accuracy:.2f}%')\n",
    "    for source in fold_source_accuracies:\n",
    "        mean_source = np.mean(fold_source_accuracies[source])\n",
    "        std_source = np.std(fold_source_accuracies[source])\n",
    "        print(f'Source {source} - Mean: {mean_source:.2f}%, Std Dev: {std_source:.2f}%')\n",
    "\n",
    "print(f'Best Hyperparameters: {best_hyperparams}, with mean accuracy: {best_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap sampling and testing\n",
    "def bootstrap_train_and_test(model, train_data, test_loader, criterion, optimizer_params, num_epochs=10, num_bootstrap=5, sample_percentage=0.8):\n",
    "    bootstrap_accuracies = []\n",
    "    source_bootstrap_accuracies = {source: [] for source in 'ABCDEF'}\n",
    "    for i in range(num_bootstrap):\n",
    "        # Create a bootstrap sample from the training data\n",
    "        indices = np.random.choice(len(train_data), size=int(sample_percentage * len(train_data)), replace=False)\n",
    "        bootstrap_subset = Subset(train_data, indices)\n",
    "        bootstrap_loader = DataLoader(bootstrap_subset, batch_size=128, shuffle=True)\n",
    "\n",
    "        # Initialize and train the model\n",
    "        optimizer = torch.optim.Adam(model.parameters(), **optimizer_params)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            for images, labels, source_labels, participant_ids in bootstrap_loader:\n",
    "                # Convert source_labels to tensor of source IDs\n",
    "                source_ids = torch.tensor(map_source_labels_to_indices(source_labels), dtype=torch.long)\n",
    "                source_ids = source_ids.unsqueeze(1).float()  # Convert to float and unsqueeze\n",
    "                \n",
    "                # Concatenate the source IDs with the input data\n",
    "                inputs = torch.cat((images, source_ids), dim=1)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Evaluate on the test set\n",
    "        model.eval()\n",
    "        test_loss, correct, total = 0, 0, 0\n",
    "        source_counts = {s: 0 for s in 'ABCDEF'}\n",
    "        source_correct = {s: 0 for s in 'ABCDEF'}\n",
    "        with torch.no_grad():\n",
    "            for images, labels, source_labels, participant_ids in test_loader:\n",
    "                # Convert source_labels to tensor of source IDs\n",
    "                source_ids = torch.tensor(map_source_labels_to_indices(source_labels), dtype=torch.long)\n",
    "                source_ids = source_ids.unsqueeze(1).float()  # Convert to float and unsqueeze\n",
    "\n",
    "                # Concatenate the source IDs with the input data\n",
    "                inputs = torch.cat((images, source_ids), dim=1)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item() * labels.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "                for i, source in enumerate(source_labels):\n",
    "                    source_counts[source] += 1\n",
    "                    if predicted[i] == labels[i]:\n",
    "                        source_correct[source] += 1\n",
    "\n",
    "        accuracy = correct / total * 100.0\n",
    "        bootstrap_accuracies.append(accuracy)\n",
    "        source_accuracies = {s: (source_correct[s] / source_counts[s] * 100) if source_counts[s] > 0 else 0 for s in 'ABCDEF'}\n",
    "        for source in source_accuracies:\n",
    "            source_bootstrap_accuracies[source].append(source_accuracies[source])\n",
    "\n",
    "    mean_accuracy = np.mean(bootstrap_accuracies)\n",
    "    std_accuracy = np.std(bootstrap_accuracies)\n",
    "    mean_source_accuracies = {s: np.mean(source_bootstrap_accuracies[s]) for s in 'ABCDEF'}\n",
    "    std_source_accuracies = {s: np.std(source_bootstrap_accuracies[s]) for s in 'ABCDEF'}\n",
    "\n",
    "    return mean_accuracy, std_accuracy, mean_source_accuracies, std_source_accuracies\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Perform bootstrap training and testing\n",
    "mean_bootstrap, std_bootstrap, mean_source_accuracies, std_source_accuracies = bootstrap_train_and_test(\n",
    "    best_model, train_dataset, test_loader, criterion, {'lr': best_hyperparams['lr']}, num_epochs=10\n",
    ")\n",
    "\n",
    "print(f'Bootstrap results: Mean accuracy: {mean_bootstrap:.2f}%, Std Dev: {std_bootstrap:.2f}%')\n",
    "for source in mean_source_accuracies:\n",
    "    print(f'Source {source} - Bootstrap Mean: {mean_source_accuracies[source]:.2f}%, Std Dev: {std_source_accuracies[source]:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
