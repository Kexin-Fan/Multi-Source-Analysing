{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from scipy import stats\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign source names to the dataset equally\n",
    "def assign_sources_equally(dataset, sources=('A', 'B', 'C', 'D', 'E', 'F')):\n",
    "    num_sources = len(sources)\n",
    "    num_data = len(dataset)\n",
    "    num_each = num_data // num_sources\n",
    "    \n",
    "    # Convert sources to a list if it's a tuple\n",
    "    sources_list = list(sources)\n",
    "    \n",
    "    # Create a list of source labels, each repeated equally\n",
    "    source_labels = sources_list * num_each + [sources_list[i] for i in range(num_data % num_sources)]\n",
    "    \n",
    "    # Shuffle the labels to randomize their order\n",
    "    np.random.shuffle(source_labels)\n",
    "    \n",
    "    return source_labels\n",
    "\n",
    "# Assign sources to training and test data\n",
    "training_sources = assign_sources_equally(training_data)\n",
    "test_sources = assign_sources_equally(test_data)\n",
    "\n",
    "# Example of how you can use the assigned sources\n",
    "print(\"First 10 source labels for training data:\", training_sources[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign participants to train and test datasets\n",
    "def assign_participants_to_train_and_test(train_labels, test_labels, num_train_participants_per_source, train_images_per_participant, num_test_participants_per_source):\n",
    "    train_participants = {source: [] for source in set(train_labels)}\n",
    "    test_participants = {source: [] for source in set(test_labels)}\n",
    "    \n",
    "    # Calculate number of test images for participants\n",
    "    num_test_participants_total = num_test_participants_per_source * len(test_participants)\n",
    "    test_images_per_participant = 10000 // num_test_participants_total\n",
    "    extra_test_images = 10000 % num_test_participants_total\n",
    "\n",
    "    # Assign participants for training\n",
    "    global_participant_id = 0\n",
    "    for source in train_participants:\n",
    "        train_indices = [i for i, s in enumerate(train_labels) if s == source]\n",
    "        np.random.shuffle(train_indices)\n",
    "        \n",
    "        for i in range(num_train_participants_per_source):\n",
    "            train_participant_indices = train_indices[i * train_images_per_participant: (i + 1) * train_images_per_participant]\n",
    "            train_participants[source].append((global_participant_id, train_participant_indices))\n",
    "            global_participant_id += 1\n",
    "\n",
    "    # Assign participants for testing\n",
    "    for source in test_participants:\n",
    "        test_indices = [i for i, s in enumerate(test_labels) if s == source]\n",
    "        np.random.shuffle(test_indices)\n",
    "        \n",
    "        for i in range(num_test_participants_per_source):\n",
    "            if i < extra_test_images:\n",
    "                test_participant_indices = test_indices[i * (test_images_per_participant + 1): (i + 1) * (test_images_per_participant + 1)]\n",
    "            else:\n",
    "                test_participant_indices = test_indices[i * test_images_per_participant: (i + 1) * test_images_per_participant]\n",
    "            test_participants[source].append((global_participant_id, test_participant_indices))\n",
    "            global_participant_id += 1\n",
    "\n",
    "    return train_participants, test_participants\n",
    "\n",
    "def count_unique_participants(participants):\n",
    "    unique_participants = set()\n",
    "    for source, participant_info in participants.items():\n",
    "        for participant_id, _ in participant_info:\n",
    "            unique_participants.add(participant_id)\n",
    "    return len(unique_participants)\n",
    "\n",
    "# Example data\n",
    "training_data_indices = np.arange(60000)\n",
    "test_data_indices = np.arange(10000)\n",
    "\n",
    "# Assign sources to training and test data\n",
    "training_sources = assign_sources_equally(training_data_indices)\n",
    "test_sources = assign_sources_equally(test_data_indices)\n",
    "\n",
    "# Parameters\n",
    "num_train_participants_per_source = 10\n",
    "num_test_participants_per_source = 2\n",
    "train_images_per_participant = 1000\n",
    "\n",
    "# Assign participant IDs to both training and test data\n",
    "train_participants, test_participants = assign_participants_to_train_and_test(\n",
    "    training_sources, test_sources, num_train_participants_per_source, train_images_per_participant, num_test_participants_per_source)\n",
    "\n",
    "# Count unique participants in training and test datasets separately\n",
    "num_unique_train_participants = count_unique_participants(train_participants)\n",
    "num_unique_test_participants = count_unique_participants(test_participants)\n",
    "\n",
    "print(f\"Number of unique participants in training data: {num_unique_train_participants}\")\n",
    "print(f\"Number of unique participants in test data: {num_unique_test_participants}\")\n",
    "\n",
    "# Example of how you can use the assigned participants\n",
    "for source, participant_info in train_participants.items():\n",
    "    print(f\"Source: {source}\")\n",
    "    for participant_id, train_indices in participant_info:\n",
    "        print(f\"  Participant {participant_id} - Train Indices: {train_indices[:10]}...\")\n",
    "\n",
    "for source, participant_info in test_participants.items():\n",
    "    print(f\"Source: {source}\")\n",
    "    for participant_id, test_indices in participant_info:\n",
    "        print(f\"  Participant {participant_id} - Test Indices: {test_indices[:10]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATED: Create custom dataset class\n",
    "class ParticipantCustomMNIST(Dataset):\n",
    "    def __init__(self, mnist_dataset, source_labels, participants, transform=None):\n",
    "        self.mnist_dataset = mnist_dataset\n",
    "        self.source_labels = source_labels\n",
    "        self.participants = participants\n",
    "        self.transform = transform\n",
    "\n",
    "        self.data = self._create_data()\n",
    "\n",
    "    def _create_data(self):\n",
    "        data = []\n",
    "        for source, participant_data in self.participants.items():\n",
    "            for participant_id, indices in participant_data:\n",
    "                for idx in indices:\n",
    "                    image, label = self.mnist_dataset[idx]  # Access original MNIST data\n",
    "                    source_label = self.source_labels[idx]\n",
    "                    data.append((image, label, source_label, participant_id))\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label, source_label, participant_id = self.data[idx]\n",
    "\n",
    "        if source_label == 'A':\n",
    "            image = transforms.functional.rotate(image, 180)\n",
    "        elif source_label == 'B':\n",
    "            c, h, w = image.shape\n",
    "            num_pixels = h * w\n",
    "            num_missing = num_pixels // 2\n",
    "            mask = torch.randperm(num_pixels)[:num_missing]\n",
    "            mask_h, mask_w = mask // w, mask % w\n",
    "            image[:, mask_h, mask_w] = 1\n",
    "        elif source_label == 'C':\n",
    "            noise = torch.randn_like(image) * 0.5\n",
    "            image = image + noise\n",
    "            image = torch.clamp(image, 0, 1)\n",
    "        elif source_label == 'D':\n",
    "            label_permutation = {0: 9, 1: 8, 2: 7, 3: 6, 4: 5, 5: 4, 6: 3, 7: 2, 8: 1, 9: 0}\n",
    "            label = label_permutation[label]\n",
    "        elif source_label == 'E':\n",
    "            pass\n",
    "        elif source_label == 'F':\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"Unknown source label provided: must be 'A', 'B', 'C', 'D', or 'E', or 'F'\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        image = torch.flatten(image)\n",
    "        return image, label, source_label, participant_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom datasets with participants\n",
    "train_dataset = ParticipantCustomMNIST(training_data, training_sources, train_participants, transform=None)\n",
    "test_dataset = ParticipantCustomMNIST(test_data, test_sources, test_participants, transform=None)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels, source_labels, participant_ids in train_loader:\n",
    "    print(\"Images shape:\", images.shape)\n",
    "    print(\"Labels shape:\", labels.shape)\n",
    "\n",
    "    print(\"Participant IDs shape:\", participant_ids.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.source_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, 100)\n",
    "        self.linear2 = nn.Linear(100,100)\n",
    "        self.linear3 = nn.Linear(100, output_size)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x = data\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        y_pred = self.linear3(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMLP(input_size=784, output_size=10)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    params=model.parameters(),\n",
    "    lr=0.001,\n",
    "    betas=(0.9,0.999)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs, target_epoch=3):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # List to store individual participant losses for the target epoch\n",
    "    target_epoch_participant_losses = []\n",
    "    \n",
    "\n",
    "    # Dictionary to store epoch losses for each source\n",
    "    epoch_losses = {'A': [], 'B': [], 'C': [], 'D': [], 'E': [], 'F': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        # Initialize source-specific counters\n",
    "        source_correct = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0}\n",
    "        source_total = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0}\n",
    "        source_running_loss = {'A': 0.0, 'B': 0.0, 'C': 0.0, 'D': 0.0, 'E': 0.0, 'F': 0.0}\n",
    "\n",
    "        # Initialize participant losses\n",
    "        participant_losses = {participant_id: [] for participant_id in range(60)}\n",
    "\n",
    "        for batch_idx, (images, labels, source_labels, participant_ids) in enumerate(train_loader):\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update running loss\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update source-specific counters and participant losses\n",
    "            for i, (source, pred, label, participant_id) in enumerate(zip(source_labels, predicted, labels, participant_ids)):\n",
    "                individual_loss = criterion(outputs[i].unsqueeze(0), label.unsqueeze(0)).item()\n",
    "                if epoch == target_epoch - 1:\n",
    "                    participant_losses[participant_id.item()].append(individual_loss)\n",
    "                source_running_loss[source] += individual_loss\n",
    "                \n",
    "                if pred == label:\n",
    "                    source_correct[source] += 1\n",
    "                source_total[source] += 1\n",
    "\n",
    "        if epoch == target_epoch - 1:\n",
    "            # Calculate average loss per participant\n",
    "            for participant_id in participant_losses:\n",
    "                if participant_losses[participant_id]:  # Avoid division by zero\n",
    "                    avg_loss = sum(participant_losses[participant_id]) / len(participant_losses[participant_id])\n",
    "                    target_epoch_participant_losses.append(avg_loss)\n",
    "\n",
    "            # Save the model state at the target epoch\n",
    "            target_epoch_model_state = model.state_dict()\n",
    "\n",
    "\n",
    "        # Calculate epoch loss and overall accuracy\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_accuracy = (correct_predictions / total_predictions) * 100\n",
    "\n",
    "        for source in source_running_loss:\n",
    "            if source_total[source] > 0:\n",
    "                epoch_source_loss = source_running_loss[source] / source_total[source]\n",
    "                epoch_losses[source].append(epoch_source_loss)\n",
    "                source_running_loss[source] = 0  # Reset running loss after calculation\n",
    "\n",
    "        # Display overall and source-specific accuracies\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "        for source in source_correct:\n",
    "            if source_total[source] > 0:\n",
    "                source_accuracy = (source_correct[source] / source_total[source]) * 100\n",
    "                print(f'Accuracy for Source {source}: {source_accuracy:.2f}%')\n",
    "\n",
    "    return target_epoch_participant_losses, epoch_losses, target_epoch_model_state\n",
    "\n",
    "target_epoch_participant_losses, epoch_losses, target_epoch_model_state = train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_at_epoch(model, test_loader, criterion, target_epoch_model_state):\n",
    "    model.load_state_dict(target_epoch_model_state)  # Load the saved model state\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    # Initialize an empty dictionary for test participant losses\n",
    "    test_participant_losses = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels, source_labels, participant_ids) in enumerate(test_loader):\n",
    "            outputs = model(images)\n",
    "            for i in range(len(labels)):\n",
    "                participant_id = participant_ids[i].item()\n",
    "                if participant_id not in test_participant_losses:\n",
    "                    test_participant_losses[participant_id] = []\n",
    "                individual_loss = criterion(outputs[i].unsqueeze(0), labels[i].unsqueeze(0)).item()\n",
    "                test_participant_losses[participant_id].append(individual_loss)\n",
    "\n",
    "    # Calculate average loss per test participant\n",
    "    target_epoch_test_participant_losses = []\n",
    "    for participant_id in test_participant_losses:\n",
    "        if test_participant_losses[participant_id]:  # Avoid division by zero\n",
    "            avg_loss = sum(test_participant_losses[participant_id]) / len(test_participant_losses[participant_id])\n",
    "            target_epoch_test_participant_losses.append(avg_loss)\n",
    "\n",
    "    return target_epoch_test_participant_losses\n",
    "\n",
    "# Example call to the evaluation function\n",
    "target_epoch_test_participant_losses = evaluate_model_at_epoch(model, test_loader, criterion, target_epoch_model_state)\n",
    "\n",
    "# Print the results\n",
    "print(\"Test participants' average losses at target epoch:\")\n",
    "for participant_id, avg_loss in enumerate(target_epoch_test_participant_losses, start=72):\n",
    "    print(f\"Participant {participant_id}: Average Loss = {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_train_participants = len(set(target_epoch_participant_losses))\n",
    "print(f\"Number of unique participants in training losses: {unique_train_participants}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_losses['E'] = [(e + f) / 2 for e, f in zip(epoch_losses['E'], epoch_losses['F'])]\n",
    "del epoch_losses['F']  # Remove the old 'F' data\n",
    "\n",
    "# Plotting the results\n",
    "for source in epoch_losses:\n",
    "    plt.plot(range(1, len(epoch_losses[source]) + 1), epoch_losses[source], marker='o', label=f'Source {source}')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Epoch Losses Over Time for Each Source')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colors to use for the plots\n",
    "colors = ['deepskyblue', 'teal', 'mediumblue', 'darkturquoise', 'aqua']\n",
    "\n",
    "# Plotting the results\n",
    "for idx, (source, color) in enumerate(zip(epoch_losses, colors)):\n",
    "    plt.plot(range(1, len(epoch_losses[source]) + 1), epoch_losses[source], marker='o', color=color, label=f'Source {source}')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "# Title removed as per your request\n",
    "\n",
    "# Remove the top and right spines\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Add grey dashed grid lines\n",
    "plt.grid(True, linestyle='--', color='grey')\n",
    "\n",
    "# Add a vertical line at epoch 3\n",
    "plt.axvline(x=3, color='orchid', linestyle='--', linewidth=1.5)\n",
    "\n",
    "# Add a horizontal legend at the top, moved up a bit\n",
    "plt.legend(loc='upper center', ncol=len(epoch_losses), bbox_to_anchor=(0.5, 1.10))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.hist(target_epoch_participant_losses, bins=30, alpha=0.7)\n",
    "plt.xlabel('Average Loss')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(f'Average Loss Distribution for Participants at Epoch 3')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Assuming target_epoch_losses is your list of individual losses at the second epoch\n",
    "losses = np.array(target_epoch_participant_losses).reshape(-1, 1)\n",
    "\n",
    "# Use the Elbow Method to find the optimal number of clusters\n",
    "wcss = []\n",
    "for i in range(1, 11):  # Test for 1 to 10 clusters\n",
    "    kmeans = KMeans(n_clusters=i, random_state=42)\n",
    "    kmeans.fit(losses)\n",
    "    wcss.append(kmeans.inertia_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Elbow graph\n",
    "plt.figure()\n",
    "plt.plot(range(1, 11), wcss, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Within-Cluster Sum of Squares (WCSS)')\n",
    "\n",
    "# Remove the top and right spines\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Add dashed grid lines\n",
    "plt.grid(True, linestyle='--', color='grey')\n",
    "\n",
    "# Add a vertical line at epoch 3\n",
    "plt.axvline(x=3, color='orchid', linestyle='--', linewidth=1.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = np.array(target_epoch_participant_losses).reshape(-1, 1)\n",
    "\n",
    "# Choose the number of clusters (e.g., 3)\n",
    "num_clusters = 3\n",
    "\n",
    "# Fit K-means clustering\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "train_clusters = kmeans.fit_predict(train_losses)\n",
    "\n",
    "# Predict clusters for the test losses\n",
    "test_losses = np.array(target_epoch_test_participant_losses).reshape(-1, 1)\n",
    "test_clusters = kmeans.predict(test_losses)\n",
    "\n",
    "# Plot the histogram with cluster information\n",
    "for cluster in range(num_clusters):\n",
    "    cluster_losses = train_losses[train_clusters == cluster]\n",
    "    plt.hist(cluster_losses, bins=30, alpha=0.7, label=f'Cluster {cluster + 1}')\n",
    "\n",
    "plt.xlabel('Loss')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Loss Distribution for Each Cluster at Epoch 3')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colors to use for the histograms\n",
    "colors = ['lightseagreen', 'cornflowerblue', 'slateblue']\n",
    "\n",
    "# Plot the histogram with cluster information\n",
    "for cluster, color in zip(range(num_clusters), colors):\n",
    "    cluster_losses = train_losses[train_clusters == cluster]\n",
    "    plt.hist(cluster_losses, bins=30, alpha=0.7, color=color, label=f'Cluster {cluster + 1}')\n",
    "\n",
    "plt.xlabel('Loss')\n",
    "plt.ylabel('Number of Participants')\n",
    "# Title removed as per your request\n",
    "\n",
    "# Remove the top and right spines\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Add grey dashed grid lines\n",
    "plt.grid(True, linestyle='--', color='grey')\n",
    "\n",
    "# Add a horizontal legend at the top, moved up a bit\n",
    "plt.legend(loc='upper center', ncol=num_clusters, bbox_to_anchor=(0.5, 1.15))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 3  # Number of clusters\n",
    "\n",
    "# Colors to use for the histograms\n",
    "colors = ['lightseagreen', 'cornflowerblue', 'slateblue']\n",
    "\n",
    "# Plot the histogram with cluster information\n",
    "plt.figure(figsize=(8, 6))\n",
    "for cluster, color in zip(range(num_clusters), colors):\n",
    "    cluster_losses = train_losses[train_clusters == cluster]\n",
    "    plt.hist(cluster_losses, bins=30, alpha=0.7, color=color, label=f'Cluster {cluster + 1}')\n",
    "\n",
    "plt.xlabel('Loss')\n",
    "plt.ylabel('Number of Participants')\n",
    "# Title removed as per your request\n",
    "\n",
    "# Remove the top and right spines\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Add grey dashed grid lines\n",
    "plt.grid(True, linestyle='--', color='grey')\n",
    "\n",
    "# Add a horizontal legend at the top, moved up a bit\n",
    "plt.legend(loc='upper center', ncol=num_clusters, bbox_to_anchor=(0.5, 1.10))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Display the number of participants in each cluster\n",
    "for cluster in range(num_clusters):\n",
    "    num_in_cluster = sum(train_clusters == cluster)\n",
    "    print(f'Number of participants in Cluster {cluster + 1}: {num_in_cluster}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the number of participants in Cluster 1\n",
    "num_in_cluster_1 = sum(train_clusters == 0)  # Assuming clusters are zero-indexed\n",
    "print(f'Number of participants in Cluster 1: {num_in_cluster_1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the mapping for train participants\n",
    "train_participant_cluster_mapping = {participant_id: cluster for participant_id, cluster in enumerate(train_clusters)}\n",
    "\n",
    "# Create the mapping for test participants\n",
    "start_test_participant_id = len(train_clusters)  # Continue the participant IDs from where train ends\n",
    "test_participant_cluster_mapping = {start_test_participant_id + participant_id: cluster for participant_id, cluster in enumerate(test_clusters)}\n",
    "\n",
    "# Combine both mappings\n",
    "participant_cluster_mapping = {**train_participant_cluster_mapping, **test_participant_cluster_mapping}\n",
    "\n",
    "# Print the combined mapping\n",
    "print(\"\\nParticipant ID to Cluster mapping:\")\n",
    "for participant_id, cluster in participant_cluster_mapping.items():\n",
    "    print(f\"Participant {participant_id}: Cluster {cluster}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract source labels and participant IDs from the train_dataset\n",
    "source_labels_dict = {}\n",
    "for i in range(len(train_dataset)):\n",
    "    _, _, source_label, participant_id = train_dataset[i]\n",
    "    if participant_id not in source_labels_dict:\n",
    "        source_labels_dict[participant_id] = source_label\n",
    "\n",
    "# Extract source labels and participant IDs from the test_dataset\n",
    "for i in range(len(test_dataset)):\n",
    "    _, _, source_label, participant_id = test_dataset[i]\n",
    "    if participant_id not in source_labels_dict:\n",
    "        source_labels_dict[participant_id] = source_label\n",
    "\n",
    "# Verify mapping\n",
    "print(\"Participant ID to Source Label mapping:\")\n",
    "for participant_id, source_label in source_labels_dict.items():\n",
    "    print(f\"Participant {participant_id}: Source {source_label}\")\n",
    "\n",
    "# Create source_labels list from the dictionary\n",
    "source_labels = [source_labels_dict[participant_id] for participant_id in sorted(source_labels_dict.keys())]\n",
    "\n",
    "# Print the source_labels list\n",
    "print(\"\\nSource Labels list:\")\n",
    "print(source_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing participant IDs\n",
    "missing_keys = [pid for pid in participant_cluster_mapping.keys() if pid not in source_labels_dict]\n",
    "print(f\"Missing participant IDs in source_labels_dict: {missing_keys}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for visualization\n",
    "data = {\n",
    "    'Participant ID': list(participant_cluster_mapping.keys()),\n",
    "    'Cluster': list(participant_cluster_mapping.values()),\n",
    "    'Source': [source_labels_dict[pid] for pid in participant_cluster_mapping.keys()]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(df['Source'], df['Cluster'])\n",
    "\n",
    "# Visualize using a heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(contingency_table, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Heatmap of Source Labels vs Clusters')\n",
    "plt.ylabel('Source')\n",
    "plt.xlabel('Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data and participant_cluster_mapping and source_labels_dict are assumed to be defined\n",
    "data = {\n",
    "    'Participant ID': list(participant_cluster_mapping.keys()),\n",
    "    'Cluster': list(participant_cluster_mapping.values()),\n",
    "    'Source': [source_labels_dict[pid] for pid in participant_cluster_mapping.keys()]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Combine 'E' and 'F' sources into 'E'\n",
    "df['Source'] = df['Source'].replace('F', 'E')\n",
    "\n",
    "# Split the DataFrame into two based on Participant ID ranges\n",
    "df1 = df[df['Participant ID'].isin(range(1, 61))]\n",
    "df2 = df[df['Participant ID'].isin(range(60, 73))]\n",
    "\n",
    "# Create contingency tables for both DataFrames\n",
    "contingency_table1 = pd.crosstab(df1['Cluster'], df1['Source'])\n",
    "contingency_table2 = pd.crosstab(df2['Cluster'], df2['Source'])\n",
    "\n",
    "# Ensure all clusters are displayed, even if they have zero data points\n",
    "for cluster in range(1, 3):\n",
    "    if cluster not in contingency_table2.index:\n",
    "        contingency_table2.loc[cluster] = 0\n",
    "contingency_table2 = contingency_table2.sort_index()\n",
    "\n",
    "# Visualize using heatmaps\n",
    "\n",
    "# First heatmap\n",
    "plt.figure(figsize=(7, 6))\n",
    "ax1 = sns.heatmap(contingency_table1, annot=True, fmt='d', cmap='Blues', cbar=True, cbar_kws={'shrink': 0.75})\n",
    "ax1.set_ylabel('Cluster')\n",
    "ax1.set_xlabel('Source')\n",
    "ax1.set_yticklabels(ax1.get_yticklabels(), rotation=0)  # Ensure labels are horizontal\n",
    "\n",
    "# Manually set y-tick labels to start from 1\n",
    "ax1.set_yticks(ax1.get_yticks())\n",
    "ax1.set_yticklabels(range(1, len(ax1.get_yticks()) + 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Second heatmap\n",
    "plt.figure(figsize=(7, 6))\n",
    "ax2 = sns.heatmap(contingency_table2, annot=True, fmt='d', cmap='Blues', cbar=True, cbar_kws={'shrink': 0.75})\n",
    "ax2.set_ylabel('Cluster')\n",
    "ax2.set_xlabel('Source')\n",
    "ax2.set_yticklabels(ax2.get_yticklabels(), rotation=0)  # Ensure labels are horizontal\n",
    "\n",
    "# Manually set y-tick labels to start from 1\n",
    "ax2.set_yticks(ax2.get_yticks())\n",
    "ax2.set_yticklabels(range(1, len(ax2.get_yticks()) + 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Initialize source-specific counters\n",
    "    source_correct = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0}\n",
    "    source_total = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0}\n",
    "    source_running_loss = {'A': 0.0, 'B': 0.0, 'C': 0.0, 'D': 0.0, 'E': 0.0, 'F': 0.0}\n",
    "\n",
    "    # Initialize participant losses\n",
    "    participant_losses = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels, source_labels, participant_ids) in enumerate(test_loader):\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update source-specific counters and participant losses\n",
    "            for i, (source, pred, label, participant_id) in enumerate(zip(source_labels, predicted, labels, participant_ids)):\n",
    "                individual_loss = criterion(outputs[i].unsqueeze(0), label.unsqueeze(0)).item()\n",
    "                if participant_id.item() not in participant_losses:\n",
    "                    participant_losses[participant_id.item()] = []\n",
    "                participant_losses[participant_id.item()].append(individual_loss)\n",
    "                source_running_loss[source] += individual_loss\n",
    "\n",
    "                if pred == label:\n",
    "                    source_correct[source] += 1\n",
    "                source_total[source] += 1\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy on the entire test set: {accuracy:.2f}%')\n",
    "\n",
    "    # Display source-specific accuracies\n",
    "    for source in source_correct:\n",
    "        if source_total[source] > 0:\n",
    "            source_accuracy = (source_correct[source] / source_total[source]) * 100\n",
    "            print(f'Accuracy for Source {source}: {source_accuracy:.2f}%')\n",
    "\n",
    "    # Calculate average loss per participant\n",
    "    participant_avg_losses = []\n",
    "    for participant_id in participant_losses:\n",
    "        if participant_losses[participant_id]:  # Avoid division by zero\n",
    "            avg_loss = sum(participant_losses[participant_id]) / len(participant_losses[participant_id])\n",
    "            participant_avg_losses.append(avg_loss)\n",
    "\n",
    "    return participant_avg_losses\n",
    "\n",
    "# Evaluate the model with source-specific accuracies and participant-specific losses\n",
    "participant_avg_losses = evaluate_model(model, test_loader, criterion)\n",
    "\n",
    "# Plot the histogram of participant losses\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(participant_avg_losses, bins=30, alpha=0.7)\n",
    "plt.xlabel('Average Loss')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Average Loss Distribution for Participants in Test Set')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMNISTWithCluster(ParticipantCustomMNIST):\n",
    "    def __init__(self, mnist_dataset, source_labels, participant_ids, participant_cluster_mapping, transform=None):\n",
    "        super().__init__(mnist_dataset, source_labels, participant_ids, transform)\n",
    "        self.participant_cluster_mapping = participant_cluster_mapping\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label, source_label, participant_id = super().__getitem__(idx)\n",
    "        loss_cluster = self.participant_cluster_mapping[participant_id]\n",
    "        return image, label, source_label, participant_id, loss_cluster\n",
    "\n",
    "# Example instantiation\n",
    "custom_train_dataset_with_cluster = CustomMNISTWithCluster(training_data, training_sources, train_participants, participant_cluster_mapping, transform=None)\n",
    "custom_test_dataset_with_cluster = CustomMNISTWithCluster(test_data, test_sources, test_participants, participant_cluster_mapping, transform=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_loss = DataLoader(custom_train_dataset_with_cluster, batch_size=128, shuffle=True)\n",
    "test_loader_loss = DataLoader(custom_test_dataset_with_cluster, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss mlp final layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossMLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, dropout_rate):\n",
    "        super(LossMLP, self).__init__()\n",
    "        # Common layers for all clusters\n",
    "        self.linear1 = nn.Linear(input_size, 100)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.linear2 = nn.Linear(100, 100)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # Special final layer for each cluster\n",
    "        self.linear3_cluster1 = nn.Linear(100, output_size)\n",
    "        self.linear3_cluster2 = nn.Linear(100, output_size)\n",
    "        self.linear3_cluster3 = nn.Linear(100, output_size)\n",
    "\n",
    "    def forward(self, data, clusters):\n",
    "        outputs = []\n",
    "        for i, cluster in enumerate(clusters):\n",
    "            x = F.relu(self.linear1(data[i]))\n",
    "            x = self.dropout1(x)\n",
    "            x = F.relu(self.linear2(x))\n",
    "            x = self.dropout2(x)\n",
    "\n",
    "            # Choose the final layer based on the loss cluster\n",
    "            if cluster == 0:\n",
    "                y_pred = self.linear3_cluster1(x)\n",
    "            elif cluster == 1:\n",
    "                y_pred = self.linear3_cluster2(x)\n",
    "            elif cluster == 2:\n",
    "                y_pred = self.linear3_cluster3(x)\n",
    "            else:\n",
    "                print(f\"Unexpected cluster: {cluster}\")\n",
    "                raise ValueError(\"Unknown cluster provided: must be 0, 1, or 2\")\n",
    "            outputs.append(y_pred)\n",
    "        return torch.stack(outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(lossmodel, train_loader, criterion, optimizerloss, num_epochs):\n",
    "    lossmodel.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        source_correct = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0}\n",
    "        source_total = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0}\n",
    "\n",
    "        for batch_idx, (images, labels, source_labels, participant_ids, loss_clusters) in enumerate(train_loader):\n",
    "            optimizerloss.zero_grad()\n",
    "            outputs = lossmodel(images, loss_clusters)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizerloss.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "            for source, pred, label in zip(source_labels, predicted, labels):\n",
    "                if pred == label:\n",
    "                    source_correct[source] += 1\n",
    "                source_total[source] += 1\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_accuracy = (correct_predictions / total_predictions) * 100\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "        for source in source_correct:\n",
    "            if source_total[source] > 0:\n",
    "                source_accuracy = (source_correct[source] / source_total[source]) * 100\n",
    "                print(f'Accuracy for Source {source}: {source_accuracy:.2f}%')\n",
    "\n",
    "def validate_model(lossmodel, val_loader, criterion):\n",
    "    lossmodel.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    source_correct = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0}\n",
    "    source_total = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels, source_labels, participant_ids, loss_clusters) in enumerate(val_loader):\n",
    "            outputs = lossmodel(images, loss_clusters)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "            for source, pred, label in zip(source_labels, predicted, labels):\n",
    "                if pred == label:\n",
    "                    source_correct[source] += 1\n",
    "                source_total[source] += 1\n",
    "\n",
    "    val_loss = val_running_loss / len(val_loader.dataset)\n",
    "    val_accuracy = correct_predictions / total_predictions * 100.0\n",
    "\n",
    "    source_accuracies = {}\n",
    "    for source in source_correct:\n",
    "        if source_total[source] > 0:\n",
    "            source_accuracy = (source_correct[source] / source_total[source]) * 100\n",
    "            source_accuracies[source] = source_accuracy\n",
    "\n",
    "    return val_loss, val_accuracy, source_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid\n",
    "hyperparameter_grid = {\n",
    "    'lr': [0.001, 0.005, 0.01],\n",
    "    'dropout_rate': [0, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model_state = None\n",
    "best_hyperparams = None\n",
    "\n",
    "# Create all possible combinations of hyperparameters\n",
    "all_combinations = list(itertools.product(*hyperparameter_grid.values()))\n",
    "\n",
    "# Cross-validation and hyperparameter tuning\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for lr, dropout_rate in all_combinations:\n",
    "    fold_accuracies = []\n",
    "    fold_source_accuracies = {'A': [], 'B': [], 'C': [], 'D': [], 'E': [], 'F': []}\n",
    "    print(f'Testing parameters: lr={lr}, dropout_rate={dropout_rate}')\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(range(len(custom_train_dataset_with_cluster)))):\n",
    "        print(f'Starting Fold {fold+1}')\n",
    "        train_subset = Subset(custom_train_dataset_with_cluster, train_idx)\n",
    "        val_subset = Subset(custom_train_dataset_with_cluster, val_idx)\n",
    "        train_loader = DataLoader(train_subset, batch_size=128, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=128, shuffle=False)\n",
    "\n",
    "        lossmodel = LossMLP(input_size=784, output_size=10, dropout_rate=dropout_rate)\n",
    "        optimizerloss = torch.optim.Adam(lossmodel.parameters(), lr=lr)\n",
    "\n",
    "        train_model(lossmodel, train_loader, criterion, optimizerloss, num_epochs=10)\n",
    "        val_loss, val_acc, source_accuracies = validate_model(lossmodel, val_loader, criterion)\n",
    "        fold_accuracies.append(val_acc)\n",
    "        for source in source_accuracies:\n",
    "            fold_source_accuracies[source].append(source_accuracies[source])\n",
    "\n",
    "    mean_accuracy = np.mean(fold_accuracies)\n",
    "    std_accuracy = np.std(fold_accuracies)\n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_hyperparams = {'lr': lr, 'dropout_rate': dropout_rate}\n",
    "        best_model = lossmodel\n",
    "\n",
    "    print(f'Parameters: lr={lr}, dropout_rate={dropout_rate}, Mean Accuracy: {mean_accuracy:.2f}%, Std Dev: {std_accuracy:.2f}%')\n",
    "    for source in fold_source_accuracies:\n",
    "        mean_source = np.mean(fold_source_accuracies[source])\n",
    "        std_source = np.std(fold_source_accuracies[source])\n",
    "        print(f'Source {source} - Mean: {mean_source:.2f}%, Std Dev: {std_source:.2f}%')\n",
    "\n",
    "print(f'Best Hyperparameters: {best_hyperparams}, with mean accuracy: {best_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap sampling and testing\n",
    "def bootstrap_train_and_test(lossmodel, train_data, test_loader, criterion, optimizer_params, num_epochs=10, num_bootstrap=5, sample_percentage=0.8):\n",
    "    bootstrap_accuracies = []\n",
    "    source_bootstrap_accuracies = {source: [] for source in 'ABCDEF'}\n",
    "    for i in range(num_bootstrap):\n",
    "        # Create a bootstrap sample from the training data\n",
    "        indices = np.random.choice(len(train_data), size=int(sample_percentage * len(train_data)), replace=True)\n",
    "        bootstrap_subset = Subset(train_data, indices)\n",
    "        bootstrap_loader = DataLoader(bootstrap_subset, batch_size=128, shuffle=True)\n",
    "\n",
    "        # Initialize and train the model\n",
    "        optimizerloss = torch.optim.Adam(lossmodel.parameters(), **optimizer_params)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            lossmodel.train()\n",
    "            for images, labels, source_labels, participant_ids, loss_clusters in bootstrap_loader:\n",
    "                optimizerloss.zero_grad()\n",
    "                outputs = lossmodel(images, loss_clusters)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizerloss.step()\n",
    "\n",
    "        # Evaluate on the test set\n",
    "        lossmodel.eval()\n",
    "        test_loss, correct, total = 0, 0, 0\n",
    "        source_counts = {s: 0 for s in 'ABCDEF'}\n",
    "        source_correct = {s: 0 for s in 'ABCDEF'}\n",
    "        with torch.no_grad():\n",
    "            for images, labels, source_labels, participant_ids, loss_clusters in test_loader:\n",
    "                outputs = lossmodel(images, loss_clusters)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item() * labels.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "                for i, source in enumerate(source_labels):\n",
    "                    source_counts[source] += 1\n",
    "                    if predicted[i] == labels[i]:\n",
    "                        source_correct[source] += 1\n",
    "\n",
    "        accuracy = correct / total * 100.0\n",
    "        bootstrap_accuracies.append(accuracy)\n",
    "        source_accuracies = {s: (source_correct[s] / source_counts[s] * 100) if source_counts[s] > 0 else 0 for s in 'ABCDEF'}\n",
    "        for source in source_accuracies:\n",
    "            source_bootstrap_accuracies[source].append(source_accuracies[source])\n",
    "\n",
    "    mean_accuracy = np.mean(bootstrap_accuracies)\n",
    "    std_accuracy = np.std(bootstrap_accuracies)\n",
    "    mean_source_accuracies = {s: np.mean(source_bootstrap_accuracies[s]) for s in 'ABCDEF'}\n",
    "    std_source_accuracies = {s: np.std(source_bootstrap_accuracies[s]) for s in 'ABCDEF'}\n",
    "\n",
    "    return mean_accuracy, std_accuracy, mean_source_accuracies, std_source_accuracies\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Perform bootstrap training and testing\n",
    "mean_bootstrap, std_bootstrap, mean_source_accuracies, std_source_accuracies = bootstrap_train_and_test(\n",
    "    best_model, custom_train_dataset_with_cluster, test_loader_loss, criterion, {'lr': best_hyperparams['lr']}, num_epochs=10, num_bootstrap=5, sample_percentage=0.8\n",
    ")\n",
    "\n",
    "print(f'Bootstrap results: Mean accuracy: {mean_bootstrap:.2f}%, Std Dev: {std_bootstrap:.2f}%')\n",
    "for source in mean_source_accuracies:\n",
    "    print(f'Source {source} - Bootstrap Mean: {mean_source_accuracies[source]:.2f}%, Std Dev: {std_source_accuracies[source]:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss mlp separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossSeparateMLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, dropout_rate):\n",
    "        super(LossSeparateMLP, self).__init__()\n",
    "        # Separate layers for source A\n",
    "        self.linear1_1 = nn.Linear(input_size, 100)\n",
    "        self.dropout1_1 = nn.Dropout(dropout_rate)\n",
    "        self.linear2_1 = nn.Linear(100, 100)\n",
    "        self.dropout2_1 = nn.Dropout(dropout_rate)\n",
    "        self.linear3_1 = nn.Linear(100, output_size)\n",
    "        \n",
    "        # Separate layers for source B\n",
    "        self.linear1_2 = nn.Linear(input_size, 100)\n",
    "        self.dropout1_2 = nn.Dropout(dropout_rate)\n",
    "        self.linear2_2 = nn.Linear(100, 100)\n",
    "        self.dropout2_2 = nn.Dropout(dropout_rate)\n",
    "        self.linear3_2 = nn.Linear(100, output_size)\n",
    "        \n",
    "        # Separate layers for source C\n",
    "        self.linear1_3 = nn.Linear(input_size, 100)\n",
    "        self.dropout1_3 = nn.Dropout(dropout_rate)\n",
    "        self.linear2_3 = nn.Linear(100, 100)\n",
    "        self.dropout2_3 = nn.Dropout(dropout_rate)\n",
    "        self.linear3_3 = nn.Linear(100, output_size)\n",
    "\n",
    "    def forward(self, data, clusters):\n",
    "        outputs = []\n",
    "        for i, cluster in enumerate(clusters):\n",
    "            if cluster == 0:\n",
    "                x = F.relu(self.linear1_1(data[i]))\n",
    "                x = self.dropout1_1(x)\n",
    "                x = F.relu(self.linear2_1(x))\n",
    "                x = self.dropout2_1(x)\n",
    "                y_pred = self.linear3_1(x)\n",
    "            elif cluster == 1:\n",
    "                x = F.relu(self.linear1_2(data[i]))\n",
    "                x = self.dropout1_2(x)\n",
    "                x = F.relu(self.linear2_2(x))\n",
    "                x = self.dropout2_2(x)\n",
    "                y_pred = self.linear3_2(x)\n",
    "            elif cluster == 2:\n",
    "                x = F.relu(self.linear1_3(data[i]))\n",
    "                x = self.dropout1_3(x)\n",
    "                x = F.relu(self.linear2_3(x))\n",
    "                x = self.dropout2_3(x)\n",
    "                y_pred = self.linear3_3(x)\n",
    "            else:\n",
    "                print(f\"Unexpected cluster: {cluster}\")\n",
    "                raise ValueError(\"Unknown cluster provided: must be 0, 1, or 2\")\n",
    "            outputs.append(y_pred)\n",
    "        return torch.stack(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(lossmodel, train_loader, criterion, optimizerloss, num_epochs):\n",
    "    lossmodel.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        source_correct = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0}\n",
    "        source_total = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0}\n",
    "\n",
    "        for batch_idx, (images, labels, source_labels, participant_ids, loss_clusters) in enumerate(train_loader):\n",
    "            optimizerloss.zero_grad()\n",
    "            outputs = lossmodel(images, loss_clusters)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizerloss.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "            for source, pred, label in zip(source_labels, predicted, labels):\n",
    "                if pred == label:\n",
    "                    source_correct[source] += 1\n",
    "                source_total[source] += 1\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_accuracy = (correct_predictions / total_predictions) * 100\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "        for source in source_correct:\n",
    "            if source_total[source] > 0:\n",
    "                source_accuracy = (source_correct[source] / source_total[source]) * 100\n",
    "                print(f'Accuracy for Source {source}: {source_accuracy:.2f}%')\n",
    "\n",
    "def validate_model(lossmodel, val_loader, criterion):\n",
    "    lossmodel.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    source_correct = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0}\n",
    "    source_total = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'E': 0, 'F': 0}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels, source_labels, participant_ids, loss_clusters) in enumerate(val_loader):\n",
    "            outputs = lossmodel(images, loss_clusters)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "            for source, pred, label in zip(source_labels, predicted, labels):\n",
    "                if pred == label:\n",
    "                    source_correct[source] += 1\n",
    "                source_total[source] += 1\n",
    "\n",
    "    val_loss = val_running_loss / len(val_loader.dataset)\n",
    "    val_accuracy = correct_predictions / total_predictions * 100.0\n",
    "\n",
    "    source_accuracies = {}\n",
    "    for source in source_correct:\n",
    "        if source_total[source] > 0:\n",
    "            source_accuracy = (source_correct[source] / source_total[source]) * 100\n",
    "            source_accuracies[source] = source_accuracy\n",
    "\n",
    "    return val_loss, val_accuracy, source_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid\n",
    "hyperparameter_grid = {\n",
    "    'lr': [0.001, 0.005, 0.01],\n",
    "    'dropout_rate': [0, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model_state = None\n",
    "best_hyperparams = None\n",
    "\n",
    "# Create all possible combinations of hyperparameters\n",
    "all_combinations = list(itertools.product(*hyperparameter_grid.values()))\n",
    "\n",
    "# Cross-validation and hyperparameter tuning\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for lr, dropout_rate in all_combinations:\n",
    "    fold_accuracies = []\n",
    "    fold_source_accuracies = {'A': [], 'B': [], 'C': [], 'D': [], 'E': [], 'F': []}\n",
    "    print(f'Testing parameters: lr={lr}, dropout_rate={dropout_rate}')\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(range(len(custom_train_dataset_with_cluster)))):\n",
    "        print(f'Starting Fold {fold+1}')\n",
    "        train_subset = Subset(custom_train_dataset_with_cluster, train_idx)\n",
    "        val_subset = Subset(custom_train_dataset_with_cluster, val_idx)\n",
    "        train_loader = DataLoader(train_subset, batch_size=128, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=128, shuffle=False)\n",
    "\n",
    "        lossmodel = LossSeparateMLP(input_size=784, output_size=10, dropout_rate=dropout_rate)\n",
    "        optimizerloss = torch.optim.Adam(lossmodel.parameters(), lr=lr)\n",
    "\n",
    "        train_model(lossmodel, train_loader, criterion, optimizerloss, num_epochs=10)\n",
    "        val_loss, val_acc, source_accuracies = validate_model(lossmodel, val_loader, criterion)\n",
    "        fold_accuracies.append(val_acc)\n",
    "        for source in source_accuracies:\n",
    "            fold_source_accuracies[source].append(source_accuracies[source])\n",
    "\n",
    "    mean_accuracy = np.mean(fold_accuracies)\n",
    "    std_accuracy = np.std(fold_accuracies)\n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_hyperparams = {'lr': lr, 'dropout_rate': dropout_rate}\n",
    "        best_model = lossmodel\n",
    "\n",
    "    print(f'Parameters: lr={lr}, dropout_rate={dropout_rate}, Mean Accuracy: {mean_accuracy:.2f}%, Std Dev: {std_accuracy:.2f}%')\n",
    "    for source in fold_source_accuracies:\n",
    "        mean_source = np.mean(fold_source_accuracies[source])\n",
    "        std_source = np.std(fold_source_accuracies[source])\n",
    "        print(f'Source {source} - Mean: {mean_source:.2f}%, Std Dev: {std_source:.2f}%')\n",
    "\n",
    "print(f'Best Hyperparameters: {best_hyperparams}, with mean accuracy: {best_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap sampling and testing\n",
    "def bootstrap_train_and_test(lossmodel, train_data, test_loader, criterion, optimizer_params, num_epochs=10, num_bootstrap=5, sample_percentage=0.8):\n",
    "    bootstrap_accuracies = []\n",
    "    source_bootstrap_accuracies = {source: [] for source in 'ABCDEF'}\n",
    "    for i in range(num_bootstrap):\n",
    "        # Create a bootstrap sample from the training data\n",
    "        indices = np.random.choice(len(train_data), size=int(sample_percentage * len(train_data)), replace=False)\n",
    "        bootstrap_subset = Subset(train_data, indices)\n",
    "        bootstrap_loader = DataLoader(bootstrap_subset, batch_size=128, shuffle=True)\n",
    "\n",
    "        # Initialize and train the model\n",
    "        optimizerloss = torch.optim.Adam(lossmodel.parameters(), **optimizer_params)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            lossmodel.train()\n",
    "            for images, labels, source_labels, participant_ids, loss_clusters in bootstrap_loader:\n",
    "                optimizerloss.zero_grad()\n",
    "                outputs = lossmodel(images, loss_clusters)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizerloss.step()\n",
    "\n",
    "        # Evaluate on the test set\n",
    "        lossmodel.eval()\n",
    "        test_loss, correct, total = 0, 0, 0\n",
    "        source_counts = {s: 0 for s in 'ABCDEF'}\n",
    "        source_correct = {s: 0 for s in 'ABCDEF'}\n",
    "        with torch.no_grad():\n",
    "            for images, labels, source_labels, participant_ids, loss_clusters in test_loader:\n",
    "                outputs = lossmodel(images, loss_clusters)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item() * labels.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "                for i, source in enumerate(source_labels):\n",
    "                    source_counts[source] += 1\n",
    "                    if predicted[i] == labels[i]:\n",
    "                        source_correct[source] += 1\n",
    "\n",
    "        accuracy = correct / total * 100.0\n",
    "        bootstrap_accuracies.append(accuracy)\n",
    "        source_accuracies = {s: (source_correct[s] / source_counts[s] * 100) if source_counts[s] > 0 else 0 for s in 'ABCDEF'}\n",
    "        for source in source_accuracies:\n",
    "            source_bootstrap_accuracies[source].append(source_accuracies[source])\n",
    "\n",
    "    mean_accuracy = np.mean(bootstrap_accuracies)\n",
    "    std_accuracy = np.std(bootstrap_accuracies)\n",
    "    mean_source_accuracies = {s: np.mean(source_bootstrap_accuracies[s]) for s in 'ABCDEF'}\n",
    "    std_source_accuracies = {s: np.std(source_bootstrap_accuracies[s]) for s in 'ABCDEF'}\n",
    "\n",
    "    return mean_accuracy, std_accuracy, mean_source_accuracies, std_source_accuracies\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Perform bootstrap training and testing\n",
    "mean_bootstrap, std_bootstrap, mean_source_accuracies, std_source_accuracies = bootstrap_train_and_test(\n",
    "    best_model, custom_train_dataset_with_cluster, test_loader_loss, criterion, {'lr': best_hyperparams['lr']}, num_epochs=10, num_bootstrap=5, sample_percentage=0.8\n",
    ")\n",
    "\n",
    "print(f'Bootstrap results: Mean accuracy: {mean_bootstrap:.2f}%, Std Dev: {std_bootstrap:.2f}%')\n",
    "for source in mean_source_accuracies:\n",
    "    print(f'Source {source} - Bootstrap Mean: {mean_source_accuracies[source]:.2f}%, Std Dev: {std_source_accuracies[source]:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
